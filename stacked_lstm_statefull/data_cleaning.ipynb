{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import os\n",
    "import importlib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'utils' from '/home/fei/Documents/projects/lyrics/stacked_lstm_statefull/utils.py'>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "importlib.reload(utils)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read(data_filepath, usecols):\n",
    "    dat = pd.read_csv(data_filepath, usecols=[usecols]).drop_duplicates()\n",
    "    dat.columns = ['text']\n",
    "    dat.loc[:, 'text'] += '(end)'\n",
    "    return dat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat = read('../lyrics_files/allSongs_d.csv', 'lyrics')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I'm tryna put you in the worst mood, ah\\nP1 cl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Hey, I was doing just fine before I met you\\nI...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I used to believe\\nWe were burnin' on the edge...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Baby I like your style\\n\\nGrips on your legs\\n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Yeah, yeah\\n\\nI've been down so long it look l...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text\n",
       "0  I'm tryna put you in the worst mood, ah\\nP1 cl...\n",
       "1  Hey, I was doing just fine before I met you\\nI...\n",
       "2  I used to believe\\nWe were burnin' on the edge...\n",
       "3  Baby I like your style\\n\\nGrips on your legs\\n...\n",
       "4  Yeah, yeah\\n\\nI've been down so long it look l..."
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_unique_chars(dat):\n",
    "    unique_chars = dat.loc[:, 'text'].apply(lambda x: list(set(x)))\n",
    "    unique_chars = unique_chars.sum()\n",
    "    unique_chars = sorted(np.unique(unique_chars))\n",
    "    return unique_chars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_chars = get_unique_chars(dat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_unique_chars(unique_chars, unique_tokens_filepath='unique_tokens'):\n",
    "    unique_tokens = pd.read_csv(unique_tokens_filepath, header=None, index_col=[0]).iloc[:, 0]\n",
    "    return set(unique_chars) - set(unique_tokens.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'\\x92', '@', '\\x94', '´', '¡', '<', '\\x97', '*', '¿', 'É', 'í', 'ñ', '\\x85', '\\x96', 'ú', ';', 'î', 'Í', '\\x91', 'Ó', 'ó', '>', '\\x93', 'á', 'à', '/', '\\xa0', '&', '+', '$', 'ã', 'é', 'ç'}\n"
     ]
    }
   ],
   "source": [
    "checking_outcome = check_unique_chars(unique_chars)\n",
    "print(checking_outcome)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You're getting way too big for your boots\n",
      "You're never too big for the boot\n",
      "I've got the big size twelves on my feet\n",
      "Your face ain't big for my boot\n",
      "Kick up the yout\n",
      "Man know that I kick up the yout\n",
      "Dem boy dere tried twist up the truth\n",
      "How dare you twist up the truth, look\n",
      "You're getting way too big for your boots\n",
      "You're never too big for the boot\n",
      "I've got the big size twelves on my feet\n",
      "Your face ain't big for my boot\n",
      "Kick up the yout\n",
      "Man know that I kick up the yout\n",
      "Dem boy dere tried twist up the truth\n",
      "How dare you twist up the truth\n",
      "\n",
      "Wanna come round here like a badboy? Do it\n",
      "Bun all the talking, go on then, do it\n",
      "Running through the party, bottle of BACARDÍ\n",
      "Bro's in my ear saying \"\"Stormz, don't do it\"\"\n",
      "Devil on my shoulder, I don't lack\n",
      "Hit 'em with a crowbar, I don't scrap\n",
      "Even when I'm sober, I'm so gassed\n",
      "Say you ride but there's no car and no mash (what you talking 'bout?)\n",
      "Clown, stand down\n",
      "Never had a MAC-10 or a trey pound\n",
      "You were never bad then, you ain't bad now\n",
      "Never had the MAC then, little nigga, back down\n",
      "Wait, I saw bare kicks, saw bare clothes\n",
      "Said fuck that, I can't wear those\n",
      "I don't like them, they're not my ting\n",
      "They went silent, they're all weirdos\n",
      "Like yeah, Stormz gone clear\n",
      "Never had a Tom Ford or a Moncler\n",
      "Mandem are calm, but you see my don there?\n",
      "Fuckeries, tell 'em don't do it, don't dare\n",
      "Don't care who you know from my block\n",
      "You're not Al Capone, you'll get boxed\n",
      "They can take my car and my creps\n",
      "I'll still do the road in my socks\n",
      "Like who's gonna stop me? You? Him?\n",
      "Weed in a cigarette, blue slims\n",
      "Don't be an idiot, move smart\n",
      "I've been killing it, new king\n",
      "Niggas ain't ready for my new stuff\n",
      "You're a prick by yourself, go and group up\n",
      "And when Krept went States for the BETs\n",
      "I was covering Krept like a bootcut\n",
      "Ith mad, that's a family ting, straight family ting\n",
      "Dem man are broke, no salary ting\n",
      "Had a peng ting called Amy\n",
      "Telling me to come round hers on a Valerie ting\n",
      "Hashtag Merky Academy ting\n",
      "Coming like art in a gallery ting\n",
      "Dem boy dere wanna chat about bars\n",
      "Wanna chat about crud but, but, but\n",
      "\n",
      "You're getting way too big for your boots\n",
      "You're never too big for the boot\n",
      "I've got the big size twelves on my feet\n",
      "Your face ain't big for my boot\n",
      "Kick up the yout\n",
      "Man know that I kick up the yout\n",
      "Dem boy dere tried twist up the truth\n",
      "How dare you twist up the truth, look\n",
      "\n",
      "I'm too hot\n",
      "Drug money in my shoebox\n",
      "I'm the man of the house and my shows sold out\n",
      "Like the brudda from the Boondocks\n",
      "Beats 1 in my boombox\n",
      "Still steal meat from the stew pot\n",
      "Mandem go sick when my tune drops\n",
      "Little man, that's a Hublot, not a Hublot\n",
      "What? Pronounce it right, you prick\n",
      "I go mad, yeah, I'm down to die for this\n",
      "I don't care, bro, I'm down to pipe your chick\n",
      "Mad stressed so I'm bound to light my spliffs\n",
      "Wait, I'm bound to ride for Flipz\n",
      "Real Gs gonna ride around to this\n",
      "Man, I've got no time to write a diss\n",
      "I never left my Nine to Five for this Wasteman ting\n",
      "I don't care what rave man's in\n",
      "I came here to relax but if it gets mad\n",
      "Mek a young boy take man's tings\n",
      "Try tell me I'm way too big to rebel?\n",
      "Nah, man, you're never too big to rebel\n",
      "I was in the O2 singing my lungs out\n",
      "Rudeboy, you're never too big for Adele\n",
      "Leave my yard, blow a kiss to my girl\n",
      "Salute to my sister as well\n",
      "Gotta keep trophies down at my mum's bit\n",
      "Man, I'm getting way too big for my shelf\n",
      "Man, I see bare MCs wanna sideline\n",
      "But I still got a couple bangers in the pipeline\n",
      "Man, I've got grown men @ing me bullshit\n",
      "You're getting way too old for the timeline\n",
      "You're getting way too old for a diss\n",
      "Should've looked after your kids\n",
      "Get out the booth, go home to your son\n",
      "It's never too late to commit\n",
      "It's like man love put my name in a bar\n",
      "Random flight, get a plane to Qatar\n",
      "This year, I learnt how to take care of business\n",
      "Next year, I'll learn how to play the guitar\n",
      "\n",
      "You're getting way too big for your boots\n",
      "You're never too big for the boot\n",
      "I've got the big size twelves on my feet\n",
      "Your face ain't big for my boot\n",
      "Kick up the yout\n",
      "Man know that I kick up the yout\n",
      "Dem boy dere tried twist up the truth\n",
      "How dare you twist up the truth, look\n",
      "You're getting way too big for your boots\n",
      "You're never too big for the boot\n",
      "I've got the big size twelves on my feet\n",
      "Your face ain't big for my boot\n",
      "Kick up the yout\n",
      "Man know that I kick up the yout\n",
      "Dem boy dere tried twist up the truth\n",
      "How dare you twist up the truth(end)\n"
     ]
    }
   ],
   "source": [
    "print(dat.loc[dat.text.str.contains('@'), 'text'].iloc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat = dat.text.apply(lambda x: set(list(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Append {'\\x92', '@', '\\x94', '´', '¡', '<', '\\x97', '*', '¿', 'É', 'í', 'ñ', '\\x85', '\\x96', 'ú', ';', 'î', 'Í', '\\x91', 'Ó', 'ó', '>', '\\x93', 'á', 'à', '/', '\\xa0', '&', '+', '$', 'ã', 'é', 'ç'}\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'set' type is unordered",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-71af7eebbb38>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchecking_outcome\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Append {}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchecking_outcome\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mappend_unique_chars\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchecking_outcome\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-9-bdafc7ef5365>\u001b[0m in \u001b[0;36mappend_unique_chars\u001b[0;34m(additionals, unique_tokens_filepath)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mappend_unique_chars\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0madditionals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0munique_tokens_filepath\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'unique_tokens'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0madd_series\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSeries\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0madditionals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0madd_series\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0munique_tokens_filepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'a'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheader\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/py3_5/lib/python3.5/site-packages/pandas/core/series.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data, index, dtype, name, copy, fastpath)\u001b[0m\n\u001b[1;32m    241\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfrozenset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    242\u001b[0m                 raise TypeError(\"{0!r} type is unordered\"\n\u001b[0;32m--> 243\u001b[0;31m                                 \"\".format(data.__class__.__name__))\n\u001b[0m\u001b[1;32m    244\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    245\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'set' type is unordered"
     ]
    }
   ],
   "source": [
    "if len(checking_outcome) > 0:\n",
    "    append_unique_chars(checking_outcome)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_chars = pd.read_csv('unique_tokens', header=None).loc[:, 1].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "word2ind, ind2word = utils.get_index_word_map(unique_chars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "76"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_size = len(unique_chars)\n",
    "vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "utils.save_index_word_map(word2ind, ind2word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "batches = dat.text.apply(len).value_counts()\n",
    "lengths = batches.index.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1000\n",
      "2000\n",
      "3000\n"
     ]
    }
   ],
   "source": [
    "for ind, length in enumerate(lengths):\n",
    "    if ind % 1000 == 0: print(ind)\n",
    "    cleaned = dat.loc[dat.text.apply(len) == length, 'text']\n",
    "    tokenised = np.array(utils.tokenise_cleaned_data(cleaned, word2ind).tolist())\n",
    "    try:\n",
    "        existing = pd.read_csv('data/train_{}.csv'.format(length))\n",
    "        existing.columns = list(range(length))\n",
    "        increased = pd.concat([existing, pd.DataFrame(tokenised)]).drop_duplicates()\n",
    "        increased.to_csv('data/train_{}.csv'.format(length), index=False)\n",
    "    except:\n",
    "        pd.DataFrame(tokenised).to_csv('data/train_{}.csv'.format(length), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
