{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Embedding, LSTM, Dense, Dropout, Flatten\n",
    "# from keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_embedding(filename='embedding.csv'):\n",
    "    return pd.read_csv(filename, header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "emb = load_embedding()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>40</th>\n",
       "      <th>41</th>\n",
       "      <th>42</th>\n",
       "      <th>43</th>\n",
       "      <th>44</th>\n",
       "      <th>45</th>\n",
       "      <th>46</th>\n",
       "      <th>47</th>\n",
       "      <th>48</th>\n",
       "      <th>49</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.585270</td>\n",
       "      <td>0.250145</td>\n",
       "      <td>0.469886</td>\n",
       "      <td>0.247563</td>\n",
       "      <td>-0.016136</td>\n",
       "      <td>-0.228900</td>\n",
       "      <td>-0.45698</td>\n",
       "      <td>0.184238</td>\n",
       "      <td>-0.532028</td>\n",
       "      <td>0.214238</td>\n",
       "      <td>...</td>\n",
       "      <td>0.005357</td>\n",
       "      <td>0.182222</td>\n",
       "      <td>0.264911</td>\n",
       "      <td>0.145107</td>\n",
       "      <td>-0.020590</td>\n",
       "      <td>0.970097</td>\n",
       "      <td>-0.372763</td>\n",
       "      <td>-0.182743</td>\n",
       "      <td>0.757045</td>\n",
       "      <td>-0.681987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.584020</td>\n",
       "      <td>0.390310</td>\n",
       "      <td>0.652820</td>\n",
       "      <td>-0.340300</td>\n",
       "      <td>0.194930</td>\n",
       "      <td>-0.834890</td>\n",
       "      <td>0.11929</td>\n",
       "      <td>-0.572910</td>\n",
       "      <td>-0.568440</td>\n",
       "      <td>0.729890</td>\n",
       "      <td>...</td>\n",
       "      <td>0.285860</td>\n",
       "      <td>-0.052162</td>\n",
       "      <td>-0.508180</td>\n",
       "      <td>-0.634590</td>\n",
       "      <td>0.338890</td>\n",
       "      <td>0.284160</td>\n",
       "      <td>-0.203400</td>\n",
       "      <td>-1.233800</td>\n",
       "      <td>0.467150</td>\n",
       "      <td>0.788580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.257690</td>\n",
       "      <td>0.456290</td>\n",
       "      <td>-0.769740</td>\n",
       "      <td>-0.376790</td>\n",
       "      <td>0.592720</td>\n",
       "      <td>-0.063527</td>\n",
       "      <td>0.20545</td>\n",
       "      <td>-0.573850</td>\n",
       "      <td>-0.290090</td>\n",
       "      <td>-0.136620</td>\n",
       "      <td>...</td>\n",
       "      <td>0.030498</td>\n",
       "      <td>-0.395430</td>\n",
       "      <td>-0.385150</td>\n",
       "      <td>-1.000200</td>\n",
       "      <td>0.087599</td>\n",
       "      <td>-0.310090</td>\n",
       "      <td>-0.346770</td>\n",
       "      <td>-0.314380</td>\n",
       "      <td>0.750040</td>\n",
       "      <td>0.970650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.039369</td>\n",
       "      <td>1.203600</td>\n",
       "      <td>0.354010</td>\n",
       "      <td>-0.559990</td>\n",
       "      <td>-0.520780</td>\n",
       "      <td>-0.669880</td>\n",
       "      <td>-0.75417</td>\n",
       "      <td>-0.653400</td>\n",
       "      <td>-0.232460</td>\n",
       "      <td>0.586860</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.601410</td>\n",
       "      <td>0.504030</td>\n",
       "      <td>-0.083316</td>\n",
       "      <td>0.202390</td>\n",
       "      <td>0.443000</td>\n",
       "      <td>-0.060769</td>\n",
       "      <td>-0.428070</td>\n",
       "      <td>-0.084135</td>\n",
       "      <td>0.491640</td>\n",
       "      <td>0.085654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.268200</td>\n",
       "      <td>-0.478700</td>\n",
       "      <td>0.180990</td>\n",
       "      <td>-0.538370</td>\n",
       "      <td>-0.240210</td>\n",
       "      <td>-0.562030</td>\n",
       "      <td>0.20944</td>\n",
       "      <td>0.423580</td>\n",
       "      <td>-0.461470</td>\n",
       "      <td>0.769030</td>\n",
       "      <td>...</td>\n",
       "      <td>0.005399</td>\n",
       "      <td>-0.533440</td>\n",
       "      <td>-0.187060</td>\n",
       "      <td>0.522540</td>\n",
       "      <td>0.243610</td>\n",
       "      <td>0.051387</td>\n",
       "      <td>0.272100</td>\n",
       "      <td>-0.444330</td>\n",
       "      <td>0.019464</td>\n",
       "      <td>0.627820</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 50 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         0         1         2         3         4         5        6   \\\n",
       "0 -0.585270  0.250145  0.469886  0.247563 -0.016136 -0.228900 -0.45698   \n",
       "1 -0.584020  0.390310  0.652820 -0.340300  0.194930 -0.834890  0.11929   \n",
       "2  0.257690  0.456290 -0.769740 -0.376790  0.592720 -0.063527  0.20545   \n",
       "3 -0.039369  1.203600  0.354010 -0.559990 -0.520780 -0.669880 -0.75417   \n",
       "4 -0.268200 -0.478700  0.180990 -0.538370 -0.240210 -0.562030  0.20944   \n",
       "\n",
       "         7         8         9     ...           40        41        42  \\\n",
       "0  0.184238 -0.532028  0.214238    ...     0.005357  0.182222  0.264911   \n",
       "1 -0.572910 -0.568440  0.729890    ...     0.285860 -0.052162 -0.508180   \n",
       "2 -0.573850 -0.290090 -0.136620    ...     0.030498 -0.395430 -0.385150   \n",
       "3 -0.653400 -0.232460  0.586860    ...    -0.601410  0.504030 -0.083316   \n",
       "4  0.423580 -0.461470  0.769030    ...     0.005399 -0.533440 -0.187060   \n",
       "\n",
       "         43        44        45        46        47        48        49  \n",
       "0  0.145107 -0.020590  0.970097 -0.372763 -0.182743  0.757045 -0.681987  \n",
       "1 -0.634590  0.338890  0.284160 -0.203400 -1.233800  0.467150  0.788580  \n",
       "2 -1.000200  0.087599 -0.310090 -0.346770 -0.314380  0.750040  0.970650  \n",
       "3  0.202390  0.443000 -0.060769 -0.428070 -0.084135  0.491640  0.085654  \n",
       "4  0.522540  0.243610  0.051387  0.272100 -0.444330  0.019464  0.627820  \n",
       "\n",
       "[5 rows x 50 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emb.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "emb_dim = emb.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emb_dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dict(filename):\n",
    "    with open(filename, 'r') as f:\n",
    "        return json.load(f)\n",
    "\n",
    "def load_index_word_map(word2ind_filename='word2ind', ind2word_filename='ind2word'):\n",
    "    word2ind = load_dict(word2ind_filename)\n",
    "    ind2word = load_dict(ind2word_filename)\n",
    "    return word2ind, ind2word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "word2ind, ind2word = load_index_word_map()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = len(word2ind)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_training_samples(filename='train.csv'):\n",
    "    return pd.read_csv(filename, header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_training_samples()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_valid_split(x, y, test_size=0.3, random_state=43):\n",
    "    assert len(x) == len(y), 'Feature and label must have same length.'\n",
    "    np.random.RandomState(seed=random_state)\n",
    "    length = len(x)\n",
    "    choices = list(range(length))\n",
    "    val_choices = np.random.choice(choices, int(length*test_size), replace=False).tolist()\n",
    "    train_choices = list(set(choices) - set(val_choices))\n",
    "    return x[train_choices, :], x[val_choices, :], y[train_choices, :], y[val_choices, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x, val_x, train_y, val_y = train_valid_split(dataset.values[:, :-1], dataset.values[:, -1:], test_size=0.3, random_state=43)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1946113, 10)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1946113, 1)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(834048, 1)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32930, 50)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emb.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_length = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(input_dim=vocab_size, output_dim=emb_dim, input_length=input_length, weights=[emb]))\n",
    "model.add(Dropout(.2))\n",
    "model.add(LSTM(100, activation='relu', return_sequences=True))\n",
    "model.add(Dropout(.2))\n",
    "model.add(LSTM(100, activation='relu'))\n",
    "model.add(Dropout(.2))\n",
    "model.add(Dense(100, activation='relu'))\n",
    "model.add(Dropout(.2))\n",
    "# model.add(Flatten())\n",
    "model.add(Dense(vocab_size, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, 10, 50)            1646500   \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 10, 50)            0         \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 10, 100)           60400     \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 10, 100)           0         \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (None, 100)               80400     \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 32930)             3325930   \n",
      "=================================================================\n",
      "Total params: 5,123,330\n",
      "Trainable params: 5,123,330\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1946113 samples, validate on 834048 samples\n",
      "Epoch 1/10\n",
      "1946113/1946113 [==============================] - 134s - loss: 6.1839 - acc: 0.1199 - val_loss: 5.5282 - val_acc: 0.1433\n",
      "Epoch 2/10\n",
      "1946113/1946113 [==============================] - 134s - loss: 5.3462 - acc: 0.1654 - val_loss: 4.9920 - val_acc: 0.1972\n",
      "Epoch 3/10\n",
      "1946113/1946113 [==============================] - 134s - loss: 5.0034 - acc: 0.1949 - val_loss: 4.7625 - val_acc: 0.2168\n",
      "Epoch 4/10\n",
      "1946113/1946113 [==============================] - 134s - loss: 4.8415 - acc: 0.2089 - val_loss: 4.6400 - val_acc: 0.2276\n",
      "Epoch 5/10\n",
      "1946113/1946113 [==============================] - 135s - loss: 4.7424 - acc: 0.2167 - val_loss: 4.5684 - val_acc: 0.2344\n",
      "Epoch 6/10\n",
      "1946113/1946113 [==============================] - 136s - loss: 4.6726 - acc: 0.2218 - val_loss: 4.5123 - val_acc: 0.2384\n",
      "Epoch 7/10\n",
      "1946113/1946113 [==============================] - 134s - loss: 4.6172 - acc: 0.2258 - val_loss: 4.4681 - val_acc: 0.2412\n",
      "Epoch 8/10\n",
      "1946113/1946113 [==============================] - 135s - loss: 4.5726 - acc: 0.2290 - val_loss: 4.4328 - val_acc: 0.2447\n",
      "Epoch 9/10\n",
      "1946113/1946113 [==============================] - 135s - loss: 4.5346 - acc: 0.2315 - val_loss: 4.4057 - val_acc: 0.2470\n",
      "Epoch 10/10\n",
      "1946113/1946113 [==============================] - 134s - loss: 4.5007 - acc: 0.2341 - val_loss: 4.3804 - val_acc: 0.2491\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f9f1ab104a8>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_x, train_y, validation_data=(val_x, val_y), epochs=10, batch_size=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.optimizer.lr = 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 389061 samples, validate on 166740 samples\n",
      "Epoch 1/1\n",
      "389061/389061 [==============================] - 671s - loss: 4.4999 - acc: 0.2323 - val_loss: 4.3772 - val_acc: 0.2507\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f536bd04dd8>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_x, train_y, validation_data=(val_x, val_y), epochs=1, batch_size=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.optimizer.lr = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 389061 samples, validate on 166740 samples\n",
      "Epoch 1/2\n",
      "389061/389061 [==============================] - 920s - loss: 4.0703 - acc: 0.2574 - val_loss: 4.2143 - val_acc: 0.2742\n",
      "Epoch 2/2\n",
      "389061/389061 [==============================] - 620s - loss: 3.6715 - acc: 0.2869 - val_loss: 4.1293 - val_acc: 0.2966\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f536bcc14a8>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_x, train_y, validation_data=(val_x, val_y), epochs=2, batch_size=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save model\n",
    "model.save('model20171228.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
