{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Embedding, LSTM, Dense, Dropout, Flatten\n",
    "# from keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_embedding(filename='embedding.csv'):\n",
    "    return pd.read_csv(filename, header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "emb = load_embedding()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>40</th>\n",
       "      <th>41</th>\n",
       "      <th>42</th>\n",
       "      <th>43</th>\n",
       "      <th>44</th>\n",
       "      <th>45</th>\n",
       "      <th>46</th>\n",
       "      <th>47</th>\n",
       "      <th>48</th>\n",
       "      <th>49</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.187625</td>\n",
       "      <td>0.619178</td>\n",
       "      <td>0.176551</td>\n",
       "      <td>0.700783</td>\n",
       "      <td>-0.195763</td>\n",
       "      <td>-0.539308</td>\n",
       "      <td>0.065364</td>\n",
       "      <td>-0.127384</td>\n",
       "      <td>-0.201672</td>\n",
       "      <td>0.325871</td>\n",
       "      <td>...</td>\n",
       "      <td>0.083290</td>\n",
       "      <td>-1.161312</td>\n",
       "      <td>-0.144524</td>\n",
       "      <td>-1.56650</td>\n",
       "      <td>0.874206</td>\n",
       "      <td>0.885304</td>\n",
       "      <td>-0.313262</td>\n",
       "      <td>-0.152760</td>\n",
       "      <td>0.262431</td>\n",
       "      <td>-0.770821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.584020</td>\n",
       "      <td>0.390310</td>\n",
       "      <td>0.652820</td>\n",
       "      <td>-0.340300</td>\n",
       "      <td>0.194930</td>\n",
       "      <td>-0.834890</td>\n",
       "      <td>0.119290</td>\n",
       "      <td>-0.572910</td>\n",
       "      <td>-0.568440</td>\n",
       "      <td>0.729890</td>\n",
       "      <td>...</td>\n",
       "      <td>0.285860</td>\n",
       "      <td>-0.052162</td>\n",
       "      <td>-0.508180</td>\n",
       "      <td>-0.63459</td>\n",
       "      <td>0.338890</td>\n",
       "      <td>0.284160</td>\n",
       "      <td>-0.203400</td>\n",
       "      <td>-1.233800</td>\n",
       "      <td>0.467150</td>\n",
       "      <td>0.788580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.257690</td>\n",
       "      <td>0.456290</td>\n",
       "      <td>-0.769740</td>\n",
       "      <td>-0.376790</td>\n",
       "      <td>0.592720</td>\n",
       "      <td>-0.063527</td>\n",
       "      <td>0.205450</td>\n",
       "      <td>-0.573850</td>\n",
       "      <td>-0.290090</td>\n",
       "      <td>-0.136620</td>\n",
       "      <td>...</td>\n",
       "      <td>0.030498</td>\n",
       "      <td>-0.395430</td>\n",
       "      <td>-0.385150</td>\n",
       "      <td>-1.00020</td>\n",
       "      <td>0.087599</td>\n",
       "      <td>-0.310090</td>\n",
       "      <td>-0.346770</td>\n",
       "      <td>-0.314380</td>\n",
       "      <td>0.750040</td>\n",
       "      <td>0.970650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.039369</td>\n",
       "      <td>1.203600</td>\n",
       "      <td>0.354010</td>\n",
       "      <td>-0.559990</td>\n",
       "      <td>-0.520780</td>\n",
       "      <td>-0.669880</td>\n",
       "      <td>-0.754170</td>\n",
       "      <td>-0.653400</td>\n",
       "      <td>-0.232460</td>\n",
       "      <td>0.586860</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.601410</td>\n",
       "      <td>0.504030</td>\n",
       "      <td>-0.083316</td>\n",
       "      <td>0.20239</td>\n",
       "      <td>0.443000</td>\n",
       "      <td>-0.060769</td>\n",
       "      <td>-0.428070</td>\n",
       "      <td>-0.084135</td>\n",
       "      <td>0.491640</td>\n",
       "      <td>0.085654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.268200</td>\n",
       "      <td>-0.478700</td>\n",
       "      <td>0.180990</td>\n",
       "      <td>-0.538370</td>\n",
       "      <td>-0.240210</td>\n",
       "      <td>-0.562030</td>\n",
       "      <td>0.209440</td>\n",
       "      <td>0.423580</td>\n",
       "      <td>-0.461470</td>\n",
       "      <td>0.769030</td>\n",
       "      <td>...</td>\n",
       "      <td>0.005399</td>\n",
       "      <td>-0.533440</td>\n",
       "      <td>-0.187060</td>\n",
       "      <td>0.52254</td>\n",
       "      <td>0.243610</td>\n",
       "      <td>0.051387</td>\n",
       "      <td>0.272100</td>\n",
       "      <td>-0.444330</td>\n",
       "      <td>0.019464</td>\n",
       "      <td>0.627820</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 50 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         0         1         2         3         4         5         6   \\\n",
       "0 -0.187625  0.619178  0.176551  0.700783 -0.195763 -0.539308  0.065364   \n",
       "1 -0.584020  0.390310  0.652820 -0.340300  0.194930 -0.834890  0.119290   \n",
       "2  0.257690  0.456290 -0.769740 -0.376790  0.592720 -0.063527  0.205450   \n",
       "3 -0.039369  1.203600  0.354010 -0.559990 -0.520780 -0.669880 -0.754170   \n",
       "4 -0.268200 -0.478700  0.180990 -0.538370 -0.240210 -0.562030  0.209440   \n",
       "\n",
       "         7         8         9     ...           40        41        42  \\\n",
       "0 -0.127384 -0.201672  0.325871    ...     0.083290 -1.161312 -0.144524   \n",
       "1 -0.572910 -0.568440  0.729890    ...     0.285860 -0.052162 -0.508180   \n",
       "2 -0.573850 -0.290090 -0.136620    ...     0.030498 -0.395430 -0.385150   \n",
       "3 -0.653400 -0.232460  0.586860    ...    -0.601410  0.504030 -0.083316   \n",
       "4  0.423580 -0.461470  0.769030    ...     0.005399 -0.533440 -0.187060   \n",
       "\n",
       "        43        44        45        46        47        48        49  \n",
       "0 -1.56650  0.874206  0.885304 -0.313262 -0.152760  0.262431 -0.770821  \n",
       "1 -0.63459  0.338890  0.284160 -0.203400 -1.233800  0.467150  0.788580  \n",
       "2 -1.00020  0.087599 -0.310090 -0.346770 -0.314380  0.750040  0.970650  \n",
       "3  0.20239  0.443000 -0.060769 -0.428070 -0.084135  0.491640  0.085654  \n",
       "4  0.52254  0.243610  0.051387  0.272100 -0.444330  0.019464  0.627820  \n",
       "\n",
       "[5 rows x 50 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emb.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "emb_dim = emb.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emb_dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dict(filename):\n",
    "    with open(filename, 'r') as f:\n",
    "        return json.load(f)\n",
    "\n",
    "def load_index_word_map(word2ind_filename='word2ind', ind2word_filename='ind2word'):\n",
    "    word2ind = load_dict(word2ind_filename)\n",
    "    ind2word = load_dict(ind2word_filename)\n",
    "    return word2ind, ind2word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "word2ind, ind2word = load_index_word_map()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = len(word2ind)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_training_samples(filename='train.csv'):\n",
    "    return pd.read_csv(filename, header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_training_samples()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_valid_split(x, y, test_size=0.3, random_state=43):\n",
    "    assert len(x) == len(y), 'Feature and label must have same length.'\n",
    "    np.random.RandomState(seed=random_state)\n",
    "    length = len(x)\n",
    "    choices = list(range(length))\n",
    "    val_choices = np.random.choice(choices, int(length*test_size), replace=False).tolist()\n",
    "    train_choices = list(set(choices) - set(val_choices))\n",
    "    return x[train_choices, :], x[val_choices, :], y[train_choices, :], y[val_choices, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x, val_x, train_y, val_y = train_valid_split(dataset.values[:, :-1], dataset.values[:, -1:], test_size=0.3, random_state=43)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1855374, 20)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1855374, 1)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(795160, 20)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(795160, 1)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32916, 50)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emb.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_length = train_x.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(input_dim=vocab_size, output_dim=emb_dim, input_length=input_length, weights=[emb]))\n",
    "model.add(Dropout(.2))\n",
    "model.add(LSTM(100, activation='relu', return_sequences=True))\n",
    "model.add(Dropout(.2))\n",
    "model.add(LSTM(100, activation='relu'))\n",
    "model.add(Dropout(.2))\n",
    "model.add(Dense(100, activation='relu'))\n",
    "model.add(Dropout(.2))\n",
    "# model.add(Flatten())\n",
    "model.add(Dense(vocab_size, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, 20, 50)            1645800   \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 20, 50)            0         \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 20, 100)           60400     \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 20, 100)           0         \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (None, 100)               80400     \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 32916)             3324516   \n",
      "=================================================================\n",
      "Total params: 5,121,216\n",
      "Trainable params: 5,121,216\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1855374 samples, validate on 795160 samples\n",
      "Epoch 1/10\n",
      "1855374/1855374 [==============================] - 167s - loss: 4.3847 - acc: 0.2385 - val_loss: 4.2867 - val_acc: 0.2550\n",
      "Epoch 2/10\n",
      "1855374/1855374 [==============================] - 166s - loss: 4.3599 - acc: 0.2403 - val_loss: 4.2722 - val_acc: 0.2566\n",
      "Epoch 3/10\n",
      "1855374/1855374 [==============================] - 166s - loss: 4.3368 - acc: 0.2416 - val_loss: 4.2510 - val_acc: 0.2586\n",
      "Epoch 4/10\n",
      "1855374/1855374 [==============================] - 166s - loss: 4.3168 - acc: 0.2431 - val_loss: 4.2368 - val_acc: 0.2598\n",
      "Epoch 5/10\n",
      "1855374/1855374 [==============================] - 169s - loss: 4.2977 - acc: 0.2443 - val_loss: 4.2277 - val_acc: 0.2610\n",
      "Epoch 6/10\n",
      "1855374/1855374 [==============================] - 168s - loss: 4.2807 - acc: 0.2456 - val_loss: 4.2106 - val_acc: 0.2619\n",
      "Epoch 7/10\n",
      "1855374/1855374 [==============================] - 166s - loss: 4.2661 - acc: 0.2465 - val_loss: 4.1972 - val_acc: 0.2633\n",
      "Epoch 8/10\n",
      "1855374/1855374 [==============================] - 167s - loss: 4.2518 - acc: 0.2475 - val_loss: 4.1908 - val_acc: 0.2639\n",
      "Epoch 9/10\n",
      "1855374/1855374 [==============================] - 167s - loss: 4.2372 - acc: 0.2485 - val_loss: 4.1801 - val_acc: 0.2661\n",
      "Epoch 10/10\n",
      "1855374/1855374 [==============================] - 167s - loss: 4.2262 - acc: 0.2493 - val_loss: 4.1709 - val_acc: 0.2667\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f3a1c154cf8>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_x, train_y, validation_data=(val_x, val_y), epochs=10, batch_size=5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.optimizer.lr = 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1925374 samples, validate on 825160 samples\n",
      "Epoch 1/10\n",
      "1925374/1925374 [==============================] - 136s - loss: 4.4266 - acc: 0.2345 - val_loss: 4.3302 - val_acc: 0.2491\n",
      "Epoch 2/10\n",
      "1925374/1925374 [==============================] - 137s - loss: 4.4025 - acc: 0.2360 - val_loss: 4.3159 - val_acc: 0.2507\n",
      "Epoch 3/10\n",
      "1925374/1925374 [==============================] - 136s - loss: 4.3803 - acc: 0.2373 - val_loss: 4.2970 - val_acc: 0.2518\n",
      "Epoch 4/10\n",
      "1925374/1925374 [==============================] - 137s - loss: 4.3624 - acc: 0.2386 - val_loss: 4.2829 - val_acc: 0.2533\n",
      "Epoch 5/10\n",
      "1925374/1925374 [==============================] - 136s - loss: 4.3454 - acc: 0.2396 - val_loss: 4.2711 - val_acc: 0.2543\n",
      "Epoch 6/10\n",
      "1925374/1925374 [==============================] - 137s - loss: 4.3298 - acc: 0.2405 - val_loss: 4.2616 - val_acc: 0.2554\n",
      "Epoch 7/10\n",
      "1925374/1925374 [==============================] - 137s - loss: 4.3144 - acc: 0.2413 - val_loss: 4.2509 - val_acc: 0.2564\n",
      "Epoch 8/10\n",
      "1925374/1925374 [==============================] - 138s - loss: 4.3013 - acc: 0.2422 - val_loss: 4.2446 - val_acc: 0.2574\n",
      "Epoch 9/10\n",
      "1925374/1925374 [==============================] - 136s - loss: 4.2893 - acc: 0.2432 - val_loss: 4.2343 - val_acc: 0.2573\n",
      "Epoch 10/10\n",
      "1925374/1925374 [==============================] - 136s - loss: 4.2778 - acc: 0.2438 - val_loss: 4.2266 - val_acc: 0.2590\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fe3e4115a90>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_x, train_y, validation_data=(val_x, val_y), epochs=10, batch_size=5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.optimizer.lr = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1925374 samples, validate on 825160 samples\n",
      "Epoch 1/1\n",
      "1925374/1925374 [==============================] - 137s - loss: 4.2672 - acc: 0.2445 - val_loss: 4.2199 - val_acc: 0.2597\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fe3e413a828>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_x, train_y, validation_data=(val_x, val_y), epochs=1, batch_size=5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save model\n",
    "model.save('model20171229_2.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
