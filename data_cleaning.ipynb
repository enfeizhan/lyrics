{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat = pd.read_csv('songdata.csv', usecols=['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Look at her face, it's a wonderful face  \\nAnd...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Take it easy with me, please  \\nTouch me gentl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I'll never know why I had to go  \\nWhy I had t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Making somebody happy is a question of give an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Making somebody happy is a question of give an...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text\n",
       "0  Look at her face, it's a wonderful face  \\nAnd...\n",
       "1  Take it easy with me, please  \\nTouch me gentl...\n",
       "2  I'll never know why I had to go  \\nWhy I had t...\n",
       "3  Making somebody happy is a question of give an...\n",
       "4  Making somebody happy is a question of give an..."
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "apos_end_pattern = r\"'( cause| d| em| ll| m| n| re| s| til| till| twas| ve) (?!')\"\n",
    "apos_start_pattern = r\" (d |j |l |ol |y )'\"\n",
    "apos_double_pattern = r\" ' n ' \"\n",
    "def data_cleaning(dat):\n",
    "    dat.loc[:, 'cleaned_text'] = dat.text.str.lower()\n",
    "    dat.loc[:, 'cleaned_text'] = dat.cleaned_text.str.replace(\"''cause\", \"'cause\")\n",
    "    dat.loc[:, 'cleaned_text'] = dat.cleaned_text.str.replace(\"''\", '\"')\n",
    "    dat.loc[:, 'cleaned_text'] = dat.cleaned_text.str.replace(r'[\\n!\"\\(\\),-.0-9:?\\[\\]]', lambda x: ' '+x.group(0)+' ')\n",
    "    dat.loc[:, 'cleaned_text'] = dat.cleaned_text.str.replace(\"'\", \" ' \")\n",
    "    # in' to ing\n",
    "    dat.loc[:, 'cleaned_text'] = dat.cleaned_text.str.replace(r\"\\w+in'$|\\w+in'\\s\", lambda m: m.group(0).replace(\"'\", 'g'))\n",
    "    # recover 'cause, 'd, 'em, 'll, 'm, 'n, 're, 's, 'til, 'till, 'twas\n",
    "    dat.loc[:, 'cleaned_text'] = dat.cleaned_text.str.replace(apos_end_pattern, lambda m: m.group(0)[:1]+m.group(0)[2:])\n",
    "    # recover d', j', l', ol', y'\n",
    "    dat.loc[:, 'cleaned_text'] = dat.cleaned_text.str.replace(apos_start_pattern, lambda m: m.group(0)[:-2]+m.group(0)[-1:])\n",
    "    # recover 'n'\n",
    "    dat.loc[:, 'cleaned_text'] = dat.cleaned_text.str.replace(apos_double_pattern, lambda m: m.group(0)[:2]+m.group(0)[3]+m.group(0)[-2:])\n",
    "    dat.loc[:, 'cleaned_text'] = dat.cleaned_text.str.replace(r' {2,}', ' ')\n",
    "    dat.loc[:, 'cleaned_text'] = dat.cleaned_text.str.strip()\n",
    "    dat.loc[:, 'text_list'] = dat.cleaned_text.str.split(' ')\n",
    "    return dat.loc[:, 'text_list']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned = data_cleaning(dat.head(10000).copy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    [look, at, her, face, ,, it, 's, a, wonderful,...\n",
       "1    [take, it, easy, with, me, ,, please, \\n, touc...\n",
       "2    [i, 'll, never, know, why, i, had, to, go, \\n,...\n",
       "3    [making, somebody, happy, is, a, question, of,...\n",
       "4    [making, somebody, happy, is, a, question, of,...\n",
       "Name: text_list, dtype: object"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaned.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_unique_tokens(tokens):\n",
    "    unique_tokens = sorted(list(set(tokens)))\n",
    "    return len(unique_tokens), unique_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = cleaned.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size, unique_tokens = get_unique_tokens(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32930"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['\\n', '!', '\"', \"'\", \"'cause\"]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_tokens[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_unique_tokens(unique_tokens, filename='unique_tokens'):\n",
    "    # check if all unique\n",
    "    assert len(unique_tokens) == len(set(unique_tokens)), 'Make sure all tokens unique!'\n",
    "    unique_token_series = pd.Series(unique_tokens)\n",
    "    unique_token_series.to_csv(filename, index=False, header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_unique_tokens(unique_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_index_word_map(unique_tokens):\n",
    "    # check if all unique\n",
    "    assert len(unique_tokens) == len(set(unique_tokens)), 'Make sure all tokens unique!'\n",
    "    word2ind = {}\n",
    "    ind2word = {}\n",
    "    for ind, word in enumerate(unique_tokens):\n",
    "        word2ind[word] = ind\n",
    "        ind2word[ind] = word\n",
    "    return word2ind, ind2word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "word2ind, ind2word = get_index_word_map(unique_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_dict(dict2save, filename):\n",
    "    with open(filename, 'w') as f:\n",
    "        json.dump(dict2save, f)\n",
    "\n",
    "def save_index_word_map(word2ind, ind2word, word2ind_filename='word2ind', ind2word_filename='ind2word'):\n",
    "    save_dict(word2ind, word2ind_filename)\n",
    "    save_dict(ind2word, ind2word_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_index_word_map(word2ind, ind2word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "glove = pd.read_table('glove.6B.50d.txt', sep=' ', header=None, quoting=3, na_filter=False, index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_emb(ind2word, imported_emb):\n",
    "    vocab_size = len(ind2word)\n",
    "    n_fact = imported_emb.shape[1]\n",
    "    emb = np.zeros((vocab_size, n_fact))\n",
    "    for i in range(vocab_size):\n",
    "        word = ind2word[i]\n",
    "        try:\n",
    "            emb[i] = imported_emb.loc[word]\n",
    "        except KeyError:\n",
    "            emb[i] = np.random.normal(scale=0.6, size=(n_fact,))\n",
    "    return emb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "emb = create_emb(ind2word, glove)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_embedding(embedding, filename='embedding.csv'):\n",
    "    np.savetxt(filename, embedding, delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_embedding(emb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenise_cleaned_data(dat, word2ind):\n",
    "    return dat.apply(lambda words: [word2ind[word] for word in words])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenised = tokenise_cleaned_data(cleaned, word2ind)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    [16657, 1464, 13086, 9847, 19, 14707, 12, 36, ...\n",
       "1    [28629, 14707, 8824, 32363, 17689, 19, 21701, ...\n",
       "2    [13846, 7, 19356, 15648, 32161, 13846, 12503, ...\n",
       "3    [17183, 26796, 12700, 14662, 36, 22803, 19884,...\n",
       "4    [17183, 26796, 12700, 14662, 36, 22803, 19884,...\n",
       "Name: text_list, dtype: object"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenised.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_text(text_list, input_length=10):\n",
    "    list_length = len(text_list)\n",
    "    res_list = []\n",
    "    for i in range(0, list_length-input_length):\n",
    "        res_list.append(text_list[i:i+input_length+1])\n",
    "    return res_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_training_samples(pd_series):\n",
    "    transformed_texts = pd_series.apply(transform_text)\n",
    "    samples = transformed_texts.sum()\n",
    "    return pd.DataFrame(samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = make_training_samples(tokenised)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2780161, 11)"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "samples.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>16657</td>\n",
       "      <td>1464</td>\n",
       "      <td>13086</td>\n",
       "      <td>9847</td>\n",
       "      <td>19</td>\n",
       "      <td>14707</td>\n",
       "      <td>12</td>\n",
       "      <td>36</td>\n",
       "      <td>32437</td>\n",
       "      <td>9847</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1464</td>\n",
       "      <td>13086</td>\n",
       "      <td>9847</td>\n",
       "      <td>19</td>\n",
       "      <td>14707</td>\n",
       "      <td>12</td>\n",
       "      <td>36</td>\n",
       "      <td>32437</td>\n",
       "      <td>9847</td>\n",
       "      <td>0</td>\n",
       "      <td>912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>13086</td>\n",
       "      <td>9847</td>\n",
       "      <td>19</td>\n",
       "      <td>14707</td>\n",
       "      <td>12</td>\n",
       "      <td>36</td>\n",
       "      <td>32437</td>\n",
       "      <td>9847</td>\n",
       "      <td>0</td>\n",
       "      <td>912</td>\n",
       "      <td>14707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9847</td>\n",
       "      <td>19</td>\n",
       "      <td>14707</td>\n",
       "      <td>12</td>\n",
       "      <td>36</td>\n",
       "      <td>32437</td>\n",
       "      <td>9847</td>\n",
       "      <td>0</td>\n",
       "      <td>912</td>\n",
       "      <td>14707</td>\n",
       "      <td>17710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>19</td>\n",
       "      <td>14707</td>\n",
       "      <td>12</td>\n",
       "      <td>36</td>\n",
       "      <td>32437</td>\n",
       "      <td>9847</td>\n",
       "      <td>0</td>\n",
       "      <td>912</td>\n",
       "      <td>14707</td>\n",
       "      <td>17710</td>\n",
       "      <td>26809</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      0      1      2      3      4      5      6      7      8      9      10\n",
       "0  16657   1464  13086   9847     19  14707     12     36  32437   9847      0\n",
       "1   1464  13086   9847     19  14707     12     36  32437   9847      0    912\n",
       "2  13086   9847     19  14707     12     36  32437   9847      0    912  14707\n",
       "3   9847     19  14707     12     36  32437   9847      0    912  14707  17710\n",
       "4     19  14707     12     36  32437   9847      0    912  14707  17710  26809"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "samples.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_training_samples(samples, filename='train.csv'):\n",
    "    samples.to_csv('train.csv', index=False, header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_training_samples(samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
