{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat = pd.read_csv('songdata.csv', usecols=['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Look at her face, it's a wonderful face  \\nAnd...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Take it easy with me, please  \\nTouch me gentl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I'll never know why I had to go  \\nWhy I had t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Making somebody happy is a question of give an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Making somebody happy is a question of give an...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text\n",
       "0  Look at her face, it's a wonderful face  \\nAnd...\n",
       "1  Take it easy with me, please  \\nTouch me gentl...\n",
       "2  I'll never know why I had to go  \\nWhy I had t...\n",
       "3  Making somebody happy is a question of give an...\n",
       "4  Making somebody happy is a question of give an..."
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_cleaning(dat):\n",
    "    dat.loc[:, 'cleaned_text'] = dat.text.str.lower()\n",
    "    dat.loc[:, 'cleaned_text'] = dat.cleaned_text.str.replace(r'[\\n!\"\\(\\),-.0-9:?\\[\\]]', lambda x: ' '+x.group(0)+' ')\n",
    "    dat.loc[:, 'cleaned_text'] = dat.cleaned_text.str.replace(\"''\", '\"')\n",
    "    dat.loc[:, 'cleaned_text'] = dat.cleaned_text.str.replace(r\"\\w+in'$|\\w+in'\\s\", lambda m: m.group(0).replace(\"'\", 'g'))\n",
    "    dat.loc[:, 'cleaned_text'] = dat.cleaned_text.str.replace(\"'\", \" ' \")\n",
    "    dat.loc[:, 'cleaned_text'] = dat.cleaned_text.str.replace(r' {2,}', ' ')\n",
    "    dat.loc[:, 'text_list'] = dat.cleaned_text.str.split(' ')\n",
    "    return dat.loc[:, 'text_list']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned = data_cleaning(dat.head(1000).copy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    [look, at, her, face, ,, it, ', s, a, wonderfu...\n",
       "1    [take, it, easy, with, me, ,, please, \\n, touc...\n",
       "2    [i, ', ll, never, know, why, i, had, to, go, \\...\n",
       "3    [making, somebody, happy, is, a, question, of,...\n",
       "4    [making, somebody, happy, is, a, question, of,...\n",
       "Name: text_list, dtype: object"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaned.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_unique_tokens(tokens):\n",
    "    unique_tokens = sorted(list(set(tokens)))\n",
    "    return len(unique_tokens), unique_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = cleaned.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size, unique_tokens = get_unique_tokens(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8762\n"
     ]
    }
   ],
   "source": [
    "print(vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_unique_tokens(unique_tokens, filename='unique_tokens'):\n",
    "    # check if all unique\n",
    "    assert len(unique_tokens) == len(set(unique_tokens)), 'Make sure all tokens unique!'\n",
    "    unique_token_series = pd.Series(unique_tokens)\n",
    "    unique_token_series.to_csv(filename, index=False, header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_unique_tokens(unique_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_index_word_map(unique_tokens):\n",
    "    # check if all unique\n",
    "    assert len(unique_tokens) == len(set(unique_tokens)), 'Make sure all tokens unique!'\n",
    "    word2ind = {}\n",
    "    ind2word = {}\n",
    "    for ind, word in enumerate(unique_tokens):\n",
    "        word2ind[word] = ind\n",
    "        ind2word[ind] = word\n",
    "    return word2ind, ind2word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "word2ind, ind2word = get_index_word_map(unique_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_dict(dict2save, filename):\n",
    "    with open(filename, 'w') as f:\n",
    "        json.dump(dict2save, f)\n",
    "\n",
    "def save_index_word_map(word2ind, ind2word, word2ind_filename='word2ind', ind2word_filename='ind2word'):\n",
    "    save_dict(word2ind, word2ind_filename)\n",
    "    save_dict(ind2word, ind2word_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_index_word_map(word2ind, ind2word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "glove = pd.read_table('glove.6B.50d.txt', sep=' ', header=None, quoting=3, na_filter=False, index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_emb(ind2word, imported_emb):\n",
    "    vocab_size = len(ind2word)\n",
    "    n_fact = imported_emb.shape[1]\n",
    "    emb = np.zeros((vocab_size, n_fact))\n",
    "    for i in range(vocab_size):\n",
    "        word = ind2word[i]\n",
    "        try:\n",
    "            emb[i] = imported_emb.loc[word]\n",
    "        except KeyError:\n",
    "            emb[i] = np.random.normal(scale=0.6, size=(n_fact,))\n",
    "    return emb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "emb = create_emb(ind2word, glove)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_embedding(embedding, filename='embedding.csv'):\n",
    "    np.savetxt(filename, embedding, delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_embedding(emb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenise_cleaned_data(dat, word2ind):\n",
    "    return dat.apply(lambda words: [word2ind[word] for word in words])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenised = tokenise_cleaned_data(cleaned, word2ind)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    [4413, 397, 3515, 2562, 8, 3926, 5, 6415, 25, ...\n",
       "1    [7600, 3926, 2324, 8594, 4666, 8, 5694, 1, 791...\n",
       "2    [3730, 5, 4375, 5069, 4149, 8534, 3730, 3356, ...\n",
       "3    [4552, 7073, 3402, 3914, 25, 5975, 5199, 3128,...\n",
       "4    [4552, 7073, 3402, 3914, 25, 5975, 5199, 3128,...\n",
       "Name: text_list, dtype: object"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenised.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_text(text_list, input_length=10):\n",
    "    list_length = len(text_list)\n",
    "    res_list = []\n",
    "    for i in range(0, list_length-input_length):\n",
    "        res_list.append(text_list[i:i+input_length+1])\n",
    "    return res_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_training_samples(pd_series):\n",
    "    transformed_texts = pd_series.apply(transform_text)\n",
    "    samples = transformed_texts.sum()\n",
    "    return pd.DataFrame(samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = make_training_samples(tokenised)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(293470, 11)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "samples.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4413</td>\n",
       "      <td>397</td>\n",
       "      <td>3515</td>\n",
       "      <td>2562</td>\n",
       "      <td>8</td>\n",
       "      <td>3926</td>\n",
       "      <td>5</td>\n",
       "      <td>6415</td>\n",
       "      <td>25</td>\n",
       "      <td>8618</td>\n",
       "      <td>2562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>397</td>\n",
       "      <td>3515</td>\n",
       "      <td>2562</td>\n",
       "      <td>8</td>\n",
       "      <td>3926</td>\n",
       "      <td>5</td>\n",
       "      <td>6415</td>\n",
       "      <td>25</td>\n",
       "      <td>8618</td>\n",
       "      <td>2562</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3515</td>\n",
       "      <td>2562</td>\n",
       "      <td>8</td>\n",
       "      <td>3926</td>\n",
       "      <td>5</td>\n",
       "      <td>6415</td>\n",
       "      <td>25</td>\n",
       "      <td>8618</td>\n",
       "      <td>2562</td>\n",
       "      <td>1</td>\n",
       "      <td>261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2562</td>\n",
       "      <td>8</td>\n",
       "      <td>3926</td>\n",
       "      <td>5</td>\n",
       "      <td>6415</td>\n",
       "      <td>25</td>\n",
       "      <td>8618</td>\n",
       "      <td>2562</td>\n",
       "      <td>1</td>\n",
       "      <td>261</td>\n",
       "      <td>3926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8</td>\n",
       "      <td>3926</td>\n",
       "      <td>5</td>\n",
       "      <td>6415</td>\n",
       "      <td>25</td>\n",
       "      <td>8618</td>\n",
       "      <td>2562</td>\n",
       "      <td>1</td>\n",
       "      <td>261</td>\n",
       "      <td>3926</td>\n",
       "      <td>4677</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     0     1     2     3     4     5     6     7     8     9     10\n",
       "0  4413   397  3515  2562     8  3926     5  6415    25  8618  2562\n",
       "1   397  3515  2562     8  3926     5  6415    25  8618  2562     1\n",
       "2  3515  2562     8  3926     5  6415    25  8618  2562     1   261\n",
       "3  2562     8  3926     5  6415    25  8618  2562     1   261  3926\n",
       "4     8  3926     5  6415    25  8618  2562     1   261  3926  4677"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "samples.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_training_samples(samples, filename='train.csv'):\n",
    "    samples.to_csv('train.csv', index=False, header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_training_samples(samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
