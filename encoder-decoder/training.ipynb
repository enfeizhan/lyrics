{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'utils' from '/home/fei/Documents/projects/lyrics/encoder-decoder/utils.py'>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "importlib.reload(utils)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Model, load_model\n",
    "from keras.layers import Input, Embedding, LSTM, Dense, Dropout, Flatten\n",
    "from keras.models import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "emb = utils.load_embedding('../embedding.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>40</th>\n",
       "      <th>41</th>\n",
       "      <th>42</th>\n",
       "      <th>43</th>\n",
       "      <th>44</th>\n",
       "      <th>45</th>\n",
       "      <th>46</th>\n",
       "      <th>47</th>\n",
       "      <th>48</th>\n",
       "      <th>49</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.060974</td>\n",
       "      <td>-0.317879</td>\n",
       "      <td>-0.550560</td>\n",
       "      <td>-0.202091</td>\n",
       "      <td>0.760389</td>\n",
       "      <td>-1.226085</td>\n",
       "      <td>0.875159</td>\n",
       "      <td>0.459753</td>\n",
       "      <td>-1.196949</td>\n",
       "      <td>1.053209</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.597071</td>\n",
       "      <td>-0.066059</td>\n",
       "      <td>0.345023</td>\n",
       "      <td>-0.429354</td>\n",
       "      <td>0.384491</td>\n",
       "      <td>-0.397192</td>\n",
       "      <td>-0.155742</td>\n",
       "      <td>0.372814</td>\n",
       "      <td>0.742573</td>\n",
       "      <td>0.722736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.095839</td>\n",
       "      <td>-0.077554</td>\n",
       "      <td>-0.355692</td>\n",
       "      <td>1.049146</td>\n",
       "      <td>-0.590769</td>\n",
       "      <td>0.929406</td>\n",
       "      <td>-0.162880</td>\n",
       "      <td>-0.456715</td>\n",
       "      <td>-0.988432</td>\n",
       "      <td>-0.104014</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.097297</td>\n",
       "      <td>-0.756459</td>\n",
       "      <td>-0.336356</td>\n",
       "      <td>0.792779</td>\n",
       "      <td>-0.133896</td>\n",
       "      <td>-0.490780</td>\n",
       "      <td>0.375516</td>\n",
       "      <td>-0.164238</td>\n",
       "      <td>1.186742</td>\n",
       "      <td>0.085916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.584020</td>\n",
       "      <td>0.390310</td>\n",
       "      <td>0.652820</td>\n",
       "      <td>-0.340300</td>\n",
       "      <td>0.194930</td>\n",
       "      <td>-0.834890</td>\n",
       "      <td>0.119290</td>\n",
       "      <td>-0.572910</td>\n",
       "      <td>-0.568440</td>\n",
       "      <td>0.729890</td>\n",
       "      <td>...</td>\n",
       "      <td>0.285860</td>\n",
       "      <td>-0.052162</td>\n",
       "      <td>-0.508180</td>\n",
       "      <td>-0.634590</td>\n",
       "      <td>0.338890</td>\n",
       "      <td>0.284160</td>\n",
       "      <td>-0.203400</td>\n",
       "      <td>-1.233800</td>\n",
       "      <td>0.467150</td>\n",
       "      <td>0.788580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.257690</td>\n",
       "      <td>0.456290</td>\n",
       "      <td>-0.769740</td>\n",
       "      <td>-0.376790</td>\n",
       "      <td>0.592720</td>\n",
       "      <td>-0.063527</td>\n",
       "      <td>0.205450</td>\n",
       "      <td>-0.573850</td>\n",
       "      <td>-0.290090</td>\n",
       "      <td>-0.136620</td>\n",
       "      <td>...</td>\n",
       "      <td>0.030498</td>\n",
       "      <td>-0.395430</td>\n",
       "      <td>-0.385150</td>\n",
       "      <td>-1.000200</td>\n",
       "      <td>0.087599</td>\n",
       "      <td>-0.310090</td>\n",
       "      <td>-0.346770</td>\n",
       "      <td>-0.314380</td>\n",
       "      <td>0.750040</td>\n",
       "      <td>0.970650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.695426</td>\n",
       "      <td>0.591739</td>\n",
       "      <td>-0.397985</td>\n",
       "      <td>1.042686</td>\n",
       "      <td>0.069218</td>\n",
       "      <td>1.111737</td>\n",
       "      <td>-0.025059</td>\n",
       "      <td>0.280132</td>\n",
       "      <td>0.155576</td>\n",
       "      <td>-0.393120</td>\n",
       "      <td>...</td>\n",
       "      <td>0.651884</td>\n",
       "      <td>-0.799066</td>\n",
       "      <td>0.226521</td>\n",
       "      <td>0.059271</td>\n",
       "      <td>0.521701</td>\n",
       "      <td>-0.369458</td>\n",
       "      <td>0.217679</td>\n",
       "      <td>-0.987510</td>\n",
       "      <td>-0.522543</td>\n",
       "      <td>0.546550</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 50 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         0         1         2         3         4         5         6   \\\n",
       "0 -0.060974 -0.317879 -0.550560 -0.202091  0.760389 -1.226085  0.875159   \n",
       "1 -0.095839 -0.077554 -0.355692  1.049146 -0.590769  0.929406 -0.162880   \n",
       "2 -0.584020  0.390310  0.652820 -0.340300  0.194930 -0.834890  0.119290   \n",
       "3  0.257690  0.456290 -0.769740 -0.376790  0.592720 -0.063527  0.205450   \n",
       "4 -0.695426  0.591739 -0.397985  1.042686  0.069218  1.111737 -0.025059   \n",
       "\n",
       "         7         8         9     ...           40        41        42  \\\n",
       "0  0.459753 -1.196949  1.053209    ...    -0.597071 -0.066059  0.345023   \n",
       "1 -0.456715 -0.988432 -0.104014    ...    -1.097297 -0.756459 -0.336356   \n",
       "2 -0.572910 -0.568440  0.729890    ...     0.285860 -0.052162 -0.508180   \n",
       "3 -0.573850 -0.290090 -0.136620    ...     0.030498 -0.395430 -0.385150   \n",
       "4  0.280132  0.155576 -0.393120    ...     0.651884 -0.799066  0.226521   \n",
       "\n",
       "         43        44        45        46        47        48        49  \n",
       "0 -0.429354  0.384491 -0.397192 -0.155742  0.372814  0.742573  0.722736  \n",
       "1  0.792779 -0.133896 -0.490780  0.375516 -0.164238  1.186742  0.085916  \n",
       "2 -0.634590  0.338890  0.284160 -0.203400 -1.233800  0.467150  0.788580  \n",
       "3 -1.000200  0.087599 -0.310090 -0.346770 -0.314380  0.750040  0.970650  \n",
       "4  0.059271  0.521701 -0.369458  0.217679 -0.987510 -0.522543  0.546550  \n",
       "\n",
       "[5 rows x 50 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emb.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "emb_dim = emb.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emb_dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "word2ind, ind2word = utils.load_index_word_map('../word2ind', '../ind2word')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = len(word2ind)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = utils.load_training_samples()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x, val_x, train_y, val_y = utils.train_valid_split(dataset.values[:, :-1], dataset.values[:, -1:], test_size=0.3, random_state=43)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7961414, 100)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7961414, 1)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3412034, 100)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3412034, 1)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_length = train_x.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model('model20180127_3.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "emb = model.get_weights()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "emb_dim = emb.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define an input sequence and process it.\n",
    "encoder_inputs = Input(shape=(None,))\n",
    "embedding = Embedding(vocab_size, emb_dim)\n",
    "encoder_embedding_outputs = embedding(encoder_inputs)\n",
    "encoder_lstm_dim = 100\n",
    "_, state_h, state_c = LSTM(encoder_lstm_dim, return_state=True)(encoder_embedding_outputs)\n",
    "encoder_states = [state_h, state_c]\n",
    "\n",
    "# Set up the decoder, using `encoder_states` as initial state.\n",
    "decoder_inputs = Input(shape=(None,))\n",
    "decoder_embedding_outputs = embedding(decoder_inputs)\n",
    "decoder_lstm_dim = 100\n",
    "decoder_lstm_outputs = LSTM(decoder_lstm_dim, return_sequences=True)(decoder_embedding_outputs, initial_state=encoder_states)\n",
    "decoder_outputs = Dense(vocab_size, activation='softmax')(decoder_lstm_outputs)\n",
    "\n",
    "# Define the model that will turn\n",
    "# `encoder_input_data` & `decoder_input_data` into `decoder_target_data`\n",
    "model = Model([encoder_inputs, decoder_inputs], decoder_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile & run training\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note that `decoder_target_data` needs to be one-hot encoded,\n",
    "# rather than sequences of integers like `decoder_input_data`!\n",
    "model.fit([encoder_input_data, decoder_input_data], decoder_target_data,\n",
    "          batch_size=2,\n",
    "          epochs=epochs,\n",
    "          validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "input_3 (InputLayer)             (None, None)          0                                            \n",
      "____________________________________________________________________________________________________\n",
      "input_4 (InputLayer)             (None, None)          0                                            \n",
      "____________________________________________________________________________________________________\n",
      "embedding_2 (Embedding)          (None, None, 50)      4072600     input_3[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "embedding_3 (Embedding)          (None, None, 50)      4072600     input_4[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "lstm_3 (LSTM)                    [(None, 100), (None,  60400       embedding_2[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "lstm_4 (LSTM)                    (None, None, 100)     60400       embedding_3[0][0]                \n",
      "                                                                   lstm_3[0][1]                     \n",
      "                                                                   lstm_3[0][2]                     \n",
      "____________________________________________________________________________________________________\n",
      "dense_2 (Dense)                  (None, None, 81452)   8226652     lstm_4[0][0]                     \n",
      "====================================================================================================\n",
      "Total params: 16,492,652\n",
      "Trainable params: 16,492,652\n",
      "Non-trainable params: 0\n",
      "____________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_model = Model(encoder_inputs, encoder_states)\n",
    "decoder_state_input_h = Input(shape=(latent_dim,))\n",
    "decoder_state_input_c = Input(shape=(latent_dim,))\n",
    "decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n",
    "decoder_lstm_outputs, state_h, state_c = decoder_lstm(\n",
    "    decoder_inputs, initial_state=decoder_states_inputs)\n",
    "decoder_states = [state_h, state_c]\n",
    "decoder_outputs = decoder_dense(decoder_lstm_outputs)\n",
    "decoder_model = Model(\n",
    "    [decoder_inputs] + decoder_states_inputs,\n",
    "    [decoder_outputs] + decoder_states)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_sequence(input_seq):\n",
    "    # Encode the input as state vectors.\n",
    "    states_value = encoder_model.predict(input_seq)\n",
    "\n",
    "    # Generate empty target sequence of length 1.\n",
    "    target_seq = np.zeros((1, 1, num_decoder_tokens))\n",
    "    # Populate the first character of target sequence with the start character.\n",
    "    target_seq[0, 0, target_token_index['\\t']] = 1.\n",
    "\n",
    "    # Sampling loop for a batch of sequences\n",
    "    # (to simplify, here we assume a batch of size 1).\n",
    "    stop_condition = False\n",
    "    decoded_sentence = ''\n",
    "    while not stop_condition:\n",
    "        output_tokens, h, c = decoder_model.predict([target_seq] + states_value)\n",
    "        # Sample a token\n",
    "        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
    "        sampled_char = ind2word[str(sampled_token_index)]\n",
    "        decoded_sentence += sampled_char\n",
    "\n",
    "        # Exit condition: either hit max length\n",
    "        # or find stop character.\n",
    "        if (sampled_char == '\\n' or\n",
    "           len(decoded_sentence) > max_decoder_seq_length):\n",
    "            stop_condition = True\n",
    "\n",
    "        # Update the target sequence (of length 1).\n",
    "        target_seq = np.zeros((1, 1, num_decoder_tokens))\n",
    "        target_seq[0, 0, sampled_token_index] = 1.\n",
    "\n",
    "        # Update states\n",
    "        states_value = [h, c]\n",
    "\n",
    "    return decoded_sentence"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
