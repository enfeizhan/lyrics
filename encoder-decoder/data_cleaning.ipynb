{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import importlib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "import utils\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'utils' from '/home/fei/Documents/projects/lyrics/encoder-decoder/utils.py'>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "importlib.reload(utils)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat = pd.read_csv('../songdata.csv', usecols=['text'], nrows=10).drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Look at her face, it's a wonderful face  \\nAnd...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Take it easy with me, please  \\nTouch me gentl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I'll never know why I had to go  \\nWhy I had t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Making somebody happy is a question of give an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Making somebody happy is a question of give an...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text\n",
       "0  Look at her face, it's a wonderful face  \\nAnd...\n",
       "1  Take it easy with me, please  \\nTouch me gentl...\n",
       "2  I'll never know why I had to go  \\nWhy I had t...\n",
       "3  Making somebody happy is a question of give an...\n",
       "4  Making somebody happy is a question of give an..."
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat.loc[:, 'text'] += '(end)'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_chars = dat.loc[:, 'text'].apply(lambda x: list(set(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    [a, z, A, s, l, p, S, f, b, n, o, ), y, i, (, ...\n",
       "1    [a, z, A, s, p, l, f, b, n, o, ), O, y, i, (, ...\n",
       "2    [a, A, l, p, s, S, B, f, b, n, o, ), y, i, (, ...\n",
       "3    [a, A, s, p, l, S, B, f, b, n, o, O, ), y, i, ...\n",
       "4    [a, A, s, p, l, S, B, f, b, n, o, O, ), y, i, ...\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_chars.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_chars = unique_chars.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_chars = sorted(np.unique(unique_chars))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "76"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(unique_chars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scanning(text, length):\n",
    "    encoder_input = []\n",
    "    decoder_input = []\n",
    "    text_length = len(text)\n",
    "    for i in range(0, text_length-2*length+1):\n",
    "        encoder_input.append(list(text[i:i+length]))\n",
    "        decoder_input.append(list(text[i+length:i+2*length]))\n",
    "    return [encoder_input, decoder_input]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "word2ind, ind2word = utils.load_index_word_map()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 183.60801649093628\n",
      "1 176.77477645874023\n",
      "2 183.21090602874756\n",
      "3 160.8573935031891\n",
      "4 173.21614909172058\n",
      "5 186.05057621002197\n",
      "6 170.08350205421448\n",
      "7 167.41624093055725\n",
      "8 206.2008502483368\n",
      "9 182.70949602127075\n",
      "10 201.82492876052856\n",
      "11 202.77631855010986\n",
      "12 185.14270853996277\n",
      "13 178.04063200950623\n",
      "14 189.43374252319336\n",
      "15 197.8701069355011\n",
      "16 195.66886830329895\n",
      "17 188.52455258369446\n",
      "18 177.9999771118164\n",
      "19 185.10700249671936\n",
      "20 187.63849353790283\n",
      "21 195.20005917549133\n",
      "22 219.81669449806213\n",
      "23 168.57537508010864\n",
      "24 191.20675826072693\n",
      "25 177.61986708641052\n",
      "26 187.3392686843872\n",
      "27 185.94926524162292\n",
      "28 179.21534776687622\n",
      "29 172.3378233909607\n",
      "30 207.19139504432678\n",
      "31 178.06361031532288\n",
      "32 202.2091088294983\n",
      "33 173.70639085769653\n",
      "34 198.87040090560913\n",
      "35 159.23995161056519\n",
      "36 224.4864203929901\n",
      "37 223.93734288215637\n",
      "38 191.61143684387207\n",
      "39 236.27651834487915\n",
      "40 201.93576955795288\n",
      "41 266.252325296402\n",
      "42 198.9865608215332\n",
      "43 201.24600911140442\n",
      "44 173.7312090396881\n",
      "45 191.04172372817993\n",
      "46 186.50812816619873\n",
      "47 174.29018783569336\n",
      "48 201.76860165596008\n",
      "49 219.67798495292664\n",
      "50 181.64640522003174\n",
      "51 189.22351050376892\n",
      "52 197.1654975414276\n",
      "53 181.56564140319824\n",
      "54 203.35341668128967\n",
      "55 173.25463819503784\n",
      "56 216.68708562850952\n",
      "57 179.15214490890503\n",
      "CPU times: user 3h 2min 33s, sys: 2min 6s, total: 3h 4min 39s\n",
      "Wall time: 3h 4min 52s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "dat_iter = pd.read_csv('../songdata.csv', usecols=['text'], chunksize=1000)\n",
    "for_encoder = []\n",
    "for_decoder = []\n",
    "for ind, dat in enumerate(dat_iter):\n",
    "    time_start = time.time()\n",
    "    dat.loc[:, 'text'] += '(end)'\n",
    "    sum_ser = dat.text.apply(lambda text: pd.Series(scanning(text, length=100), index=['for_encoder', 'for_decoder'])).sum()\n",
    "    for_encoder_se = pd.Series(sum_ser.for_encoder)\n",
    "    for_decoder_se = pd.Series(sum_ser.for_decoder)\n",
    "    encoder_input_tokenised = utils.tokenise_cleaned_data(for_encoder_se, word2ind)\n",
    "    decoder_input_tokenised = utils.tokenise_cleaned_data(for_decoder_se, word2ind)\n",
    "    decoder_target_tokenised = decoder_input_tokenised.copy()\n",
    "    decoder_input_tokenised = decoder_input_tokenised.apply(lambda x: [word2ind[' ']]+x[:-1])\n",
    "    encoder_input_tokenised = pd.DataFrame(encoder_input_tokenised.values.tolist())\n",
    "    decoder_input_tokenised = pd.DataFrame(decoder_input_tokenised.values.tolist())\n",
    "    decoder_target_tokenised = pd.DataFrame(decoder_target_tokenised.values.tolist())\n",
    "    encoder_input_tokenised.to_csv('data/encoder_input_{:02d}.csv'.format(ind), index=False)\n",
    "    decoder_input_tokenised.to_csv('data/decoder_input_{:02d}.csv'.format(ind), index=False)\n",
    "    decoder_target_tokenised.to_csv('data/decoder_target_{:02d}.csv'.format(ind), index=False)\n",
    "    time_stop = time.time()\n",
    "    print(ind, time_stop - time_start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "utils.save_unique_tokens(unique_chars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "word2ind, ind2word = utils.get_index_word_map(unique_chars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "utils.save_index_word_map(word2ind, ind2word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_input_tokenised = utils.tokenise_cleaned_data(for_encoder_se, word2ind)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    [33, 64, 64, 60, 1, 50, 69, 1, 57, 54, 67, 1, ...\n",
       "1    [64, 64, 60, 1, 50, 69, 1, 57, 54, 67, 1, 55, ...\n",
       "2    [64, 60, 1, 50, 69, 1, 57, 54, 67, 1, 55, 50, ...\n",
       "3    [60, 1, 50, 69, 1, 57, 54, 67, 1, 55, 50, 52, ...\n",
       "4    [1, 50, 69, 1, 57, 54, 67, 1, 55, 50, 52, 54, ...\n",
       "dtype: object"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder_input_tokenised.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder_input_tokenised = utils.tokenise_cleaned_data(for_decoder_se, word2ind)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    [69, 1, 68, 57, 54, 1, 68, 62, 58, 61, 54, 68,...\n",
       "1    [1, 68, 57, 54, 1, 68, 62, 58, 61, 54, 68, 1, ...\n",
       "2    [68, 57, 54, 1, 68, 62, 58, 61, 54, 68, 1, 72,...\n",
       "3    [57, 54, 1, 68, 62, 58, 61, 54, 68, 1, 72, 57,...\n",
       "4    [54, 1, 68, 62, 58, 61, 54, 68, 1, 72, 57, 54,...\n",
       "dtype: object"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoder_input_tokenised.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder_target_tokenised = decoder_input_tokenised.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    [69, 1, 68, 57, 54, 1, 68, 62, 58, 61, 54, 68,...\n",
       "1    [1, 68, 57, 54, 1, 68, 62, 58, 61, 54, 68, 1, ...\n",
       "2    [68, 57, 54, 1, 68, 62, 58, 61, 54, 68, 1, 72,...\n",
       "3    [57, 54, 1, 68, 62, 58, 61, 54, 68, 1, 72, 57,...\n",
       "4    [54, 1, 68, 62, 58, 61, 54, 68, 1, 72, 57, 54,...\n",
       "dtype: object"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoder_target_tokenised.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(decoder_target_tokenised.loc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder_input_tokenised = decoder_input_tokenised.apply(lambda x: [word2ind[' ']]+x[:-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    [1, 69, 1, 68, 57, 54, 1, 68, 62, 58, 61, 54, ...\n",
       "1    [1, 1, 68, 57, 54, 1, 68, 62, 58, 61, 54, 68, ...\n",
       "2    [1, 68, 57, 54, 1, 68, 62, 58, 61, 54, 68, 1, ...\n",
       "3    [1, 57, 54, 1, 68, 62, 58, 61, 54, 68, 1, 72, ...\n",
       "4    [1, 54, 1, 68, 62, 58, 61, 54, 68, 1, 72, 57, ...\n",
       "dtype: object"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoder_input_tokenised.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(decoder_input_tokenised.iloc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "encoder_input_tokenised = pd.DataFrame(encoder_input_tokenised.values.tolist())\n",
    "decoder_input_tokenised = pd.DataFrame(decoder_input_tokenised.values.tolist())\n",
    "decoder_target_tokenised = pd.DataFrame(decoder_target_tokenised.values.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1898365, 100)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder_input_tokenised.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1898365, 100)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoder_input_tokenised.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1898365, 100)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoder_target_tokenised.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_input_tokenised.to_csv('encoder_input.csv', index=False)\n",
    "decoder_input_tokenised.to_csv('decoder_input.csv', index=False)\n",
    "decoder_target_tokenised.to_csv('decoder_target.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
